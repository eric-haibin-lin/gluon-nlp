BERT:
  CLUSTER:
    NP: 256
    HOST: hosts_256
  
  TRAIN:
    DTYPE: float32
    LOG_INTERVAL: 100
    OPTIMIZER: lamb
    MODEL: bert_24_1024_16
    CKPT_DIR: ./ckpt-256-dir
    CKPT_INTERVAL: 50000
    EVAL_INTERVAL: 500000
  
  HVD:
    CYCLE_TIME: 85
    HIERARCHICAL: 0

  NCCL:
    MIN_NUM_RINGS: 1
  
  RUN:
    PHASE1: 0
    PHASE2: 1
  
  PHASE2:
    DATA: /data/datasets/book-wiki-split-2k-v3/*.train,
    DATA_EVAL: /data/datasets/book-wiki-split-2k-v3/*.dev,
    OPTIONS: --raw --skip_state_loading --start_step 0 --verbose
    NUM_STEPS: 15625
    BS: 32768
    ACC: 4
    MAX_SEQ_LENGTH: 128
    MAX_PREDICTIONS_PER_SEQ: 20
    LR: 0.005
    WARMUP_RATIO: 0.2

  ENV:
    SHARE_SEED: 0

CONTAINER:
  NAME: bert
  SHARED_FS: /fsx
  REGISTRY: haibinlin/bert-docker:nlp
